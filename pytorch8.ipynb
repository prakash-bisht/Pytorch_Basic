{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prakash-bisht/Pytorch_Basic/blob/master/pytorch8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ldVRN_KlXdPL"
      },
      "outputs": [],
      "source": [
        "# FP16 (half-precision floating-point) and FP32 (single-precision floating-point) are two different formats for storing and representing numbers \n",
        "# in deep learning. The main difference between them is the number of bits used for each number.\n",
        "\n",
        "# FP16 uses 16 bits for each number, which allows for a much smaller memory footprint than FP32, enabling faster training and inference time. \n",
        "# However, because it is using half the precision of FP32, there is a risk of losing accuracy when doing calculations.\n",
        "\n",
        "# FP32 uses 32 bits for each number, which allows for higher precision and accuracy. This is beneficial when accuracy is the primary concern, \n",
        "# such as with medical imaging, facial recognition, and other tasks that require high precision. However, \n",
        "# this comes at the cost of a larger memory footprint, leading to slower training and inference times.\n",
        "\n",
        "# In general, FP16 is recommended for deep learning tasks that require faster computation times and don't require a lot of precision, \n",
        "# such as image classification and object detection. FP32 is recommended for tasks that require higher precision, \n",
        "# such as medical imaging and facial recognition."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if args.fp16:\n",
        "    try:\n",
        "        from apex import amp\n",
        "    except ImportError:\n",
        "        raise ImportError(\n",
        "            \"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\"\n",
        "        )\n",
        "    model, optimizer = amp.initialize(\n",
        "        model, optimizer, opt_level=args.fp16_opt_level\n",
        "    )\n",
        "\n",
        "if args.fp16:\n",
        "    with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
        "        scaled_loss.backward()\n",
        "\n",
        "if args.fp16:\n",
        "    torch.nn.utils.clip_grad_norm_(\n",
        "        amp.master_params(optimizer), args.max_grad_norm\n",
        "    )"
      ],
      "metadata": {
        "id": "FQTaNrhsZ3GP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#cast_model_type\n",
        "\"\"\"In summary, the cast_model_type property in Apex.Amp is used to cast a model's parameters and buffers to a specified data type, \n",
        "which can help improve the efficiency of training a model by reducing the memory footprint and computational requirements.\"\"\""
      ],
      "metadata": {
        "id": "_McbO2zwZ3H3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#patch_torch_functions\n",
        "\"\"\"In summary, patch_torch_functions is a feature of Apex.Amp that automatically modifies PyTorch functions and methods\n",
        "so that they can be executed using mixed precision and Tensor Cores to accelerate training while maintaining accuracy.\"\"\""
      ],
      "metadata": {
        "id": "bHM6orhfZ3LR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#keep_batchnorm_fp32\n",
        "\"\"\"The keep_batchnorm_fp32 property in Apex.Amp allows you to specify whether to keep the batch normalization parameters in FP32 precision.\n",
        "When this property is set to True, the batch normalization parameters will be stored in FP32 precision,\n",
        "while the rest of the model will be stored in FP16 precision. This enables the use of higher precision for batch normalization while\n",
        "still allowing for mixed precision training, which can lead to faster training and better accuracy.\"\"\""
      ],
      "metadata": {
        "id": "wicAbRsAiKUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#master_weights\n",
        "\"\"\"The master_weights parameter in apex.amp is used to specify whether or not to maintain FP32 master weights for an FP16 model. \n",
        "If this parameter is set to True, the optimizer will maintain a copy of the model weights in FP32 and update these weights in each iteration.\n",
        "If it is set to False, the optimizer will only update the FP16 weights directly.\"\"\""
      ],
      "metadata": {
        "id": "OP4c_NwjiKWI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#loss_scale\n",
        "\"\"\"If loss_scale is set to a float value, it is used as a static (fixed) loss scale factor. \n",
        "This means that the gradients are multiplied by the loss scale factor before being applied to the weights. \n",
        "The optimizer step is also scaled by the inverse of the loss scale factor to keep the weights moving in the right direction.\n",
        "If loss_scale is set to \"dynamic\", it means that the loss scale factor is automatically adjusted over time during training. \n",
        "The AMP module keeps track of the gradients and adjusts the loss scale to maintain a certain threshold between the gradients and the weight updates,\n",
        "thus avoiding overflow and underflow issues. This can be useful in cases where the gradients have a wide range of values or are sparse,\n",
        "and a fixed loss scale factor may not work well.\n",
        "Using a dynamic loss scale can lead to better performance and stability in mixed-precision training, \n",
        "but it may require more overhead for maintaining the state of the optimizer and the loss scale factor.\"\"\""
      ],
      "metadata": {
        "id": "TP8vtwAyiKZ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#opt_levels\n",
        "Recognized opt_levels are \"O0\", \"O1\", \"O2\", and \"O3\"."
      ],
      "metadata": {
        "id": "-zDopOcriKbi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#O0: FP32 training\n",
        "Default properties set by O0:\n",
        "cast_model_type=torch.float32\n",
        "patch_torch_functions=False\n",
        "keep_batchnorm_fp32=None (effectively, “not applicable,” everything is FP32)\n",
        "master_weights=False\n",
        "loss_scale=1.0"
      ],
      "metadata": {
        "id": "iEU4oevHiKfI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#O1: Mixed Precision (recommended for typical use)\n",
        "Default properties set by O1:\n",
        "cast_model_type=None (not applicable)\n",
        "patch_torch_functions=True\n",
        "keep_batchnorm_fp32=None (again, not applicable, all model weights remain FP32)\n",
        "master_weights=None (not applicable, model weights remain FP32)\n",
        "loss_scale=\"dynamic\""
      ],
      "metadata": {
        "id": "5r-PzuTGiKh6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#O2: “Almost FP16” Mixed Precision\n",
        "Default properties set by O2:\n",
        "cast_model_type=torch.float16\n",
        "patch_torch_functions=False\n",
        "keep_batchnorm_fp32=True\n",
        "master_weights=True\n",
        "loss_scale=\"dynamic\""
      ],
      "metadata": {
        "id": "SC5AktMbmW2N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#O3: FP16 training\n",
        "Default properties set by O3:\n",
        "cast_model_type=torch.float16\n",
        "patch_torch_functions=False\n",
        "keep_batchnorm_fp32=False\n",
        "master_weights=False\n",
        "loss_scale=1.0"
      ],
      "metadata": {
        "id": "vwQLkF1omW36"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dir(locals()['__builtins__']),end='\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCw4OXUSANio",
        "outputId": "f58ea09c-d048-47c4-e6de-4f7af593f2f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ArithmeticError', 'AssertionError', 'AttributeError', 'BaseException', 'BlockingIOError', 'BrokenPipeError', 'BufferError', 'BytesWarning', 'ChildProcessError', 'ConnectionAbortedError', 'ConnectionError', 'ConnectionRefusedError', 'ConnectionResetError', 'DeprecationWarning', 'EOFError', 'Ellipsis', 'EnvironmentError', 'Exception', 'False', 'FileExistsError', 'FileNotFoundError', 'FloatingPointError', 'FutureWarning', 'GeneratorExit', 'IOError', 'ImportError', 'ImportWarning', 'IndentationError', 'IndexError', 'InterruptedError', 'IsADirectoryError', 'KeyError', 'KeyboardInterrupt', 'LookupError', 'MemoryError', 'ModuleNotFoundError', 'NameError', 'None', 'NotADirectoryError', 'NotImplemented', 'NotImplementedError', 'OSError', 'OverflowError', 'PendingDeprecationWarning', 'PermissionError', 'ProcessLookupError', 'RecursionError', 'ReferenceError', 'ResourceWarning', 'RuntimeError', 'RuntimeWarning', 'StopAsyncIteration', 'StopIteration', 'SyntaxError', 'SyntaxWarning', 'SystemError', 'SystemExit', 'TabError', 'TimeoutError', 'True', 'TypeError', 'UnboundLocalError', 'UnicodeDecodeError', 'UnicodeEncodeError', 'UnicodeError', 'UnicodeTranslateError', 'UnicodeWarning', 'UserWarning', 'ValueError', 'Warning', 'ZeroDivisionError', '__IPYTHON__', '__build_class__', '__debug__', '__doc__', '__import__', '__loader__', '__name__', '__package__', '__spec__', 'abs', 'all', 'any', 'ascii', 'bin', 'bool', 'breakpoint', 'bytearray', 'bytes', 'callable', 'chr', 'classmethod', 'compile', 'complex', 'copyright', 'credits', 'delattr', 'dict', 'dir', 'display', 'divmod', 'enumerate', 'eval', 'exec', 'execfile', 'filter', 'float', 'format', 'frozenset', 'get_ipython', 'getattr', 'globals', 'hasattr', 'hash', 'help', 'hex', 'id', 'input', 'int', 'isinstance', 'issubclass', 'iter', 'len', 'license', 'list', 'locals', 'map', 'max', 'memoryview', 'min', 'next', 'object', 'oct', 'open', 'ord', 'pow', 'print', 'property', 'range', 'repr', 'reversed', 'round', 'runfile', 'set', 'setattr', 'slice', 'sorted', 'staticmethod', 'str', 'sum', 'super', 'tuple', 'type', 'vars', 'zip']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "li = [4,5,6,7]\n",
        "try:\n",
        "  print(li[0])\n",
        "except IndexError:\n",
        "  raise IndexError('the lenght os list is',len(li))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_PgVjXiAQ-s",
        "outputId": "d5715ee1-739c-422a-bfc9-2161b9af67b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n"
          ]
        }
      ]
    }
  ]
}