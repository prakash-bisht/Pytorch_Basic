{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pytorch2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lz94e__FN8AF"
      },
      "source": [
        "import torch,torchvision \n",
        "model = torchvision.models.resnet18(pretrained=True)\n",
        "data = torch.rand(1,3,64,64)\n",
        "labels = torch.rand(1,1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9QR7g65OAZ7",
        "outputId": "8076f54b-60f3-4d53-ca0d-86b1bae342aa"
      },
      "source": [
        "labels.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1000])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrcGzo7HOAdq",
        "outputId": "d3bf2009-a68b-4207-ef76-7566aa1c6109"
      },
      "source": [
        "prediction = model(data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbxnTTetOAgu"
      },
      "source": [
        "loss = (prediction - labels).sum()\n",
        "loss.backward()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYYV6OqbOA9R"
      },
      "source": [
        "optim = torch.optim.SGD(model.parameters(),lr=1e-2,momentum=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPmNxRyiOBAL"
      },
      "source": [
        "optim.step()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L11IkjhhOBDL"
      },
      "source": [
        "a = torch.tensor([2.,3.],requires_grad=True)\n",
        "b = torch.tensor([6.,4.],requires_grad=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnYLzF9QOBGZ"
      },
      "source": [
        "Q = 3*a**3 - b**2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKtBXSkTOBIz"
      },
      "source": [
        "#When we call .backward() on Q, autograd calculates these gradients and stores them in the respective tensors’ .grad attribute."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ViqceIZJOBaC"
      },
      "source": [
        "\"\"\"We need to explicitly pass a gradient argument in Q.backward() because it is a vector.\n",
        "gradient is a tensor of the same shape as Q, and it represents the gradient of Q w.r.t. itself, i.e.\n",
        "dQ/dQ=1\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h27lZAIzYRaO"
      },
      "source": [
        "external_grad = torch.tensor([1.,1.])\n",
        "Q.backward(gradient=external_grad)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvKTtxKtYRdn",
        "outputId": "5bdfc802-894f-4885-cfc6-7d4e17cf3ce6"
      },
      "source": [
        "print(9*a**2 == a.grad)\n",
        "print(-2*b == b.grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([True, True])\n",
            "tensor([True, True])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFb7YS_pYRhy"
      },
      "source": [
        "'''torch.autograd tracks operations on all tensors which have their requires_grad flag set to True.\n",
        "For tensors that don’t require gradients, setting this attribute to False excludes it from the gradient computation DAG.\n",
        "The output tensor of an operation will require gradients even if only a single input tensor has requires_grad=True.'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Q28FExCOBq2",
        "outputId": "2885eb65-5a67-4360-e162-f4b9c5ba5bc3"
      },
      "source": [
        "m = torch.rand(5, 5)\n",
        "n = torch.rand(5, 5)\n",
        "z = torch.rand(5,5,requires_grad=True)\n",
        "a = m + n\n",
        "print(f\"Does `a` require gradients? : {a.requires_grad}\")\n",
        "b = m + z\n",
        "print(f\"Does `b` require gradients?: {b.requires_grad}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Does `a` require gradients? : False\n",
            "Does `b` require gradients?: True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4SSdGFwbJh_"
      },
      "source": [
        "'''In a NN, parameters that don’t compute gradients are usually called frozen parameters. \n",
        "It is useful to “freeze” part of your model if you know in advance that you \n",
        "won’t need the gradients of those parameters (this offers some performance benefits by reducing autograd computations).'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Gjf21BWbJzh"
      },
      "source": [
        "#Another common usecase where exclusion from the DAG is important is for finetuning a pretrained network"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8z-QGHR_bJ27"
      },
      "source": [
        "'''In finetuning, we freeze most of the model and typically only modify the classifier layers to make predictions on new labels.\n",
        " Let’s walk through a small example to demonstrate this. As before, we load a pretrained resnet18 model, and freeze all the parameters.'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ru4XORhgbJ6x"
      },
      "source": [
        "from torch import nn, optim\n",
        "model = torchvision.models.resnet18(pretrained=True)\n",
        "for param in model.parameters():\n",
        "  param.requires_grad = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8evIzvx4bJ9v"
      },
      "source": [
        "'''Let’s say we want to finetune the model on a new dataset with 10 labels. In resnet, the classifier is the last linear layer model.fc. \n",
        "We can simply replace it with a new linear layer (unfrozen by default) that acts as our classifier.'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qL_Gf-Rhdd96"
      },
      "source": [
        "model.fc = nn.Linear(512,10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8-B6FQXdeGN"
      },
      "source": [
        "'''Now all parameters in the model, except the parameters of model.fc, are frozen.\n",
        " The only parameters that compute gradients are the weights and bias of model.fc.'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFzTFaTfdeRj"
      },
      "source": [
        "optimizer = optim.SGD(model.parameters(),lr=1e-2,momentum=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORtDwLzPeO54"
      },
      "source": [
        "'''Notice although we register all the parameters in the optimizer, \n",
        "the only parameters that are computing gradients (and hence updated in gradient descent) are the weights and bias of the classifier.'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAnilDcLeUNa"
      },
      "source": [
        "'''torch.no_grad\n",
        "Context-manager that disabled gradient calculation.\n",
        "In this mode, the result of every computation will have requires_grad=False, even when the inputs have requires_grad=True.\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}